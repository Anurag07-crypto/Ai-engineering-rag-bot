# ğŸš€ AI Engineering RAG Bot  
*A Retrieval-Augmented Generation (RAG) Application for Learning AI Concepts*

---

## ğŸ“Œ Overview

This project is a **Retrieval-Augmented Generation (RAG) chatbot** designed to help users learn AI Engineering concepts from custom PDF documents.

Instead of relying only on pretrained knowledge, the system retrieves relevant information from a local knowledge base and generates structured educational responses using an LLM.

### Key Capabilities

- ğŸ“š Context-aware answers from PDFs
- ğŸ§  Semantic search using embeddings
- âš¡ Fast inference using Groq LLM
- ğŸ§¾ Structured educational outputs
- ğŸŒ Interactive Streamlit interface

---

## ğŸ—ï¸ Project Architecture
User Query
â”‚
â–¼
Streamlit UI
â”‚
â–¼
RAG Pipeline
â”œâ”€â”€ Embedding Manager
â”œâ”€â”€ Vector Database (ChromaDB)
â”œâ”€â”€ Retriever
â””â”€â”€ LLM (Groq - Llama 3.1)
â”‚
â–¼
Structured Educational Response

---

## ğŸ“‚ Project Structure
â”œâ”€â”€ main_pipeline.py # Streamlit app + pipeline orchestration
â”œâ”€â”€ rag.py # Retrieval logic
â”œâ”€â”€ embedding_manager.py # Embedding generation
â”œâ”€â”€ vector_db.py # ChromaDB vector storage
â”œâ”€â”€ data/ # PDF knowledge base
â”œâ”€â”€ vector_store/ # Persistent embeddings
â”œâ”€â”€ .env # API keys
â””â”€â”€ README.md

---

## âš™ï¸ Components

### 1ï¸âƒ£ Embedding Manager
Generates semantic embeddings using SentenceTransformers.

- Model: `BAAI/bge-small-en-v1.5`
- Converts text into vector embeddings.

---

### 2ï¸âƒ£ Vector Database (ChromaDB)

Stores embeddings persistently and enables similarity search.

Features:
- Automatic collection creation
- Metadata storage
- Fast retrieval

---

### 3ï¸âƒ£ RAG Retriever

Responsible for:
- Query embedding generation
- Similarity search
- Threshold filtering
- Ranked document retrieval

---

### 4ï¸âƒ£ Main Pipeline (Streamlit App)

Handles:
- PDF loading
- Text chunking
- Vector DB creation
- Prompt engineering
- Structured output generation

---

## ğŸ§  How It Works

1. PDFs are loaded from the `data/` directory.
2. Documents are split into chunks.
3. Chunks are converted into embeddings.
4. Embeddings are stored in ChromaDB.
5. User submits a query.
6. Relevant chunks are retrieved.
7. Context is sent to the LLM.
8. Structured educational response is generated.

---

## ğŸ§¾ Output Format

The chatbot returns structured learning content:

- âœ… Definition
- âœ… 3 Pros
- âœ… 3 Cons
- âœ… Use Case Explanation

---

## ğŸ”§ Installation

### 1. Clone Repository

```bash
git clone <your-repo-url>
cd rag-ai-bot
2. Create Virtual Environment
python -m venv .venv

Activate environment:

Windows

.venv\Scripts\activate

Mac/Linux

source .venv/bin/activate
3. Install Dependencies
pip install -r requirements.txt

Example dependencies:

streamlit
langchain
langchain-community
langchain-groq
chromadb
sentence-transformers
pymupdf
python-dotenv
tqdm
pydantic
4. Environment Variables

Create a .env file:

GROQ_API_KEY=your_api_key_here
â–¶ï¸ Run Application
streamlit run main_pipeline.py

Open browser:

http://localhost:8501
ğŸ“Š Features

Retrieval-Augmented Generation

Persistent Vector Database

Structured LLM Outputs

PDF Knowledge Base

Semantic Search

Streamlit UI

Educational AI Assistant

ğŸ”® Future Improvements

Multi-document upload UI

Hybrid search (keyword + semantic)

Conversation memory

FastAPI deployment

Docker support

Model switching

Evaluation dashboard

ğŸ§‘â€ğŸ’» Tech Stack

Python

LangChain

ChromaDB

Sentence Transformers

Groq (Llama 3.1)

Streamlit

PyMuPDF

ğŸ¤ Contribution

Contributions are welcome!

Fork repository

Create feature branch

Commit changes

Open Pull Request

ğŸ“œ License

MIT License â€” free to use and modify.

â­ Acknowledgement

Built as part of an AI Engineering learning journey focused on practical RAG system design and LLM integration.


---
